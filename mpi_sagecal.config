params.mpi='/usr/lib64/openmpi/bin/mpirun'

params {
    if (params.stage=="DI") {
        stage_number='002'
        beam_model = 1
        sky_model="${projectDir}/models/rescaled_new3c61.sky.txt"
        clusters_file="${projectDir}/models/rescaled_new3c61.sky.txt.cluster"
        admm_rho_file="${projectDir}/models/admm_rho_step1000.txt"
        min_lambda=50
        admm_iterations=20
        time_samples_per_sol = 15
        max_em_iterations=4
        max_lbfgs_iterations = 20
        robust_nu_upper = 30
        number_of_threads= 6
        preprocessing_file = "${projectDir}/modules/di_high_reg_preprocessing.nf" //An separate nf file to be run in parallel per node. Composed of tasks that do not need consensus e.g clipping.py
    }

    if (params.stage=="DD") {
        stage_number='003'
        beam_model = 0
        sky_model = "${projectDir}/models/sky_sagecal_no_diffuse_simple_ateam_corrected_shape.txt"
        clusters_file = "${projectDir}/models/sky_sagecal_no_diffuse_new_cluster_time_remove_outer_simple_ateam_new3c61.txt.cluster"
        admm_rho_file = "${projectDir}/models/admm_rho.txt-hight_reg_test_v2_new_cluster_time_remove_outer"
        min_lambda = 250
        admm_iterations = 41
        time_samples_per_sol = 120
        max_em_iterations = 3
        max_lbfgs_iterations = 10
        robust_nu_upper = 3
        number_of_threads = 12

        preprocessing_file = "${projectDir}/modules/dd_preprocessing.nf" //An separate nf file to be run in parallel per node. Composed of tasks that do not need consensus e.g clipping.py
    }

    // These params do not change in either DI or DD in the default lofar pipeline
    max_lambda=5000
    consensus_polynomial_terms = 3
    solver = 5
    pre_whiten = 0
    apply_global_solution = 1
    use_gpu = 1
    sky_model_format=1
    robust_nu_lower = 2
    lbfgs_memory_size = 7
    single_max_em_iterations = 2
    input_column = "DATA"
    output_column = "CORRECTED_DATA"
    solutions_file = "${params.obsid}_sage_${params.stage}_Zsol"
}